{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import *\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helpers\n",
    "def trans_sparse_matrix(coupon_detail_train, users, lists):\n",
    "    '''\n",
    "    get sparse matrix using coupon as row and user as column\n",
    "    '''\n",
    "    nrow = coupon_detail_train.shape[0]\n",
    "    \n",
    "    # hash user_id and coupon_id\n",
    "    users_hashtable = {x: i for i, x in enumerate(users.USER_ID_hash)}\n",
    "    coupon_hashtable = {x: i for i, x in enumerate(lists_train.COUPON_ID_hash)}\n",
    "    \n",
    "    row = coupon_detail_train.COUPON_ID_hash.apply(lambda x: coupon_hashtable.get(x))\n",
    "    column = coupon_detail_train.USER_ID_hash.apply(lambda x: users_hashtable.get(x))\n",
    "    \n",
    "    mat = coo_matrix((np.array([1.] * nrow), (row, column)), shape=(len(coupon_hashtable), len(users)))\n",
    "    mat = mat.tocsr()\n",
    "    return mat\n",
    "\n",
    "def get_accuracy(pred, actual):\n",
    "    '''\n",
    "    pred and actual should be in a nested dict format\n",
    "    '''\n",
    "    n = 0\n",
    "    c = 0\n",
    "    for k, v_pred in pred.iteritems():\n",
    "        n += 1\n",
    "        v_actual = actual.get(k)\n",
    "        if v_actual is None:\n",
    "            continue\n",
    "        elif set(v_actual) == set(v_pred):\n",
    "            c += 1\n",
    "        else:\n",
    "            continue\n",
    "    acc = float(c) / n\n",
    "    print 'Total predictions: %d' % n\n",
    "    print 'Correct predictions: %d' % c\n",
    "    print 'Accuracy: %.4f' % acc\n",
    "    return acc\n",
    "\n",
    "# calculate distance\n",
    "def _mod(x):\n",
    "    return np.power(np.power(x, 2).sum(), .5)\n",
    "\n",
    "def cosine(x, y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return (x * y).sum() / ( _mod(x) * _mod(y) )\n",
    "    \n",
    "def calc_sim(x, y, sim_func=cosine):\n",
    "    '''\n",
    "    x, y: vector of numeric features\n",
    "    '''\n",
    "    sim = sim_func(x, y)\n",
    "    \n",
    "    return sim\n",
    "\n",
    "def get_top_items(x, X, topn=None, sim_func=cosine):\n",
    "    if topn is None:\n",
    "        topn = len(X)-1\n",
    "    \n",
    "    sim_arr = []\n",
    "    err_arr = []\n",
    "    for _x in X:\n",
    "        _x = _x[:-1]  # remove the last element (ID)\n",
    "        sim = calc_sim(x, _x, sim_func=sim_func)\n",
    "        if np.isnan(sim):\n",
    "            err_arr.append(_x)\n",
    "        else:\n",
    "            sim_arr.append(sim)\n",
    "    \n",
    "    ret = []\n",
    "    for i in np.argsort(sim_arr)[-topn:]:\n",
    "        ret.append((X[i, -1], sim_arr[i]))\n",
    "    return ret\n",
    "\n",
    "def predict(f_test, F_train, U_train, topn=10, threshold=0.5):\n",
    "    # similarity of test coupon C_i and train coupon C_j\n",
    "    S = np.array([calc_sim(f_test, f_train) for f_train in F_train])\n",
    "    \n",
    "    # take top n most similar train coupons\n",
    "    T_idx = np.argsort(S)[::-topn]\n",
    "    \n",
    "    # calculate sum of user vector\n",
    "    U = U_train[T_idx].sum(axis=0) / topn\n",
    "    \n",
    "    return U\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "# users <- read.csv('user_list.csv')\n",
    "users = read_csv('user_list.csv', parse_dates=[0])\n",
    "\n",
    "# lists\n",
    "lists_train = read_csv('coupon_list_train.csv')\n",
    "lists_test = read_csv('coupon_list_test.csv')\n",
    "\n",
    "# coupon detail\n",
    "coupon_detail_train = read_csv('coupon_detail_train.csv')\n",
    "\n",
    "# area\n",
    "area_train = read_csv('coupon_area_train.csv')\n",
    "area_test = read_csv('coupon_area_test.csv')\n",
    "\n",
    "# visit\n",
    "visit_train = read_csv('coupon_visit_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize features of coupons\n",
    "num_vars = [\n",
    "    'PRICE_RATE',\n",
    "    'CATALOG_PRICE',\n",
    "    'DISPPERIOD',\n",
    "    'VALIDPERIOD',\n",
    "]\n",
    "bin_vars = [\n",
    "    'USABLE_DATE_MON',\n",
    "    'USABLE_DATE_TUE',\n",
    "    'USABLE_DATE_WED',\n",
    "    'USABLE_DATE_THU',\n",
    "    'USABLE_DATE_FRI',\n",
    "    'USABLE_DATE_SAT',\n",
    "    'USABLE_DATE_SUN',\n",
    "    'USABLE_DATE_HOLIDAY',\n",
    "    'USABLE_DATE_BEFORE_HOLIDAY',\n",
    "]\n",
    "for var in num_vars:\n",
    "    lists_train[var + '_norm'] = lists_train[var].astype(float) / np.std(lists_train[var])\n",
    "    lists_test[var + '_norm'] = lists_test[var].astype(float) / np.std(lists_test[var])\n",
    "    \n",
    "fit_vars = bin_vars + [x + '_norm' for x in num_vars]\n",
    "\n",
    "lists_train.ix[:, fit_vars] = lists_train.ix[:, fit_vars].fillna(0)\n",
    "lists_test.ix[:, fit_vars] = lists_test.ix[:, fit_vars].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "Y = trans_sparse_matrix(coupon_detail_train, users, lists_train)\n",
    "U = Y\n",
    "F = lists_train.ix[:, fit_vars].values\n",
    "\n",
    "U_pred = []\n",
    "for i in lists_test.index:\n",
    "    f_test = lists_test.ix[i, fit_vars].values\n",
    "    u_pred = predict(f_test, F, U).A[0]\n",
    "    \n",
    "    U_pred.append(u_pred)\n",
    "    \n",
    "    if i > 0 and (i % 10) == 0:\n",
    "        print i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT = (np.array(U_pred).T > 0.5) * 1\n",
    "OUTPUT = np.array(np.where(OUTPUT)).T\n",
    "pred = {}\n",
    "for row in OUTPUT:\n",
    "    user_id, coupon_id = users.USER_ID_hash[row[1]], lists_test.COUPON_ID_hash[row[0]]\n",
    "    if pred.get(user_id) is None:\n",
    "        pred[user_id] = []\n",
    "    pred[user_id].append(coupon_id)\n",
    "    \n",
    "with open('solution.csv', 'wb') as f:\n",
    "    f.write('USER_ID_hash,PURCHASED_COUPONS\\n')\n",
    "    for user_id in users.USER_ID_hash.tolist():\n",
    "        coupon_ids = pred.get(user_id)\n",
    "        f.write(user_id + ',')\n",
    "        f.write(','.join(coupon_ids) if coupon_ids is not None else '' + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
